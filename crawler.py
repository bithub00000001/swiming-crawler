import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
import asyncio
from telegram import Bot
import time

# GitHub Secretsì—ì„œ í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
BOT_TOKEN = os.environ['TELEGRAM_BOT_TOKEN']
CHAT_ID = os.environ['TELEGRAM_CHAT_ID']


async def send_telegram_message(message, use_html=True):
    bot = Bot(token=BOT_TOKEN)
    try:
        parse_mode = 'HTML' if use_html else None
        await bot.send_message(
            chat_id=CHAT_ID,
            text=message,
            parse_mode=parse_mode
        )
    except Exception as e:
        # HTML íŒŒì‹± ì—ëŸ¬ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„
        if use_html:
            await send_telegram_message(message, use_html=False)
        else:
            print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")


def crawl_notices():
    url = "https://www.jjss.or.kr/reserv/planweb/board/list.9is"
    params = {
        'contentUid': 'ff8080816c5f9de6016cd702efc70de1',
        'boardUid': 'ff8080816d4d1c03016d85eb2aff02cd',
        'categoryUid2': 'C1'  # ì™„ì‚°ìˆ˜ì˜ì¥
    }

    # User-Agent í—¤ë” ì¶”ê°€ (í¬ë¡¤ë§ ì°¨ë‹¨ ë°©ì§€)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }

    # ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
    max_retries = 3
    for attempt in range(max_retries):
        try:
            print(f"í¬ë¡¤ë§ ì‹œë„ {attempt + 1}/{max_retries}")
            response = requests.get(
                url,
                params=params,
                headers=headers,
                timeout=30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )
            response.raise_for_status()  # HTTP ì—ëŸ¬ í™•ì¸
            break
        except Exception as e:
            print(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            if attempt == max_retries - 1:
                raise e
            time.sleep(2)  # 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„

    soup = BeautifulSoup(response.content, 'html.parser')

    # ê³µì§€ì‚¬í•­ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ
    notices = []
    table = soup.find('table', class_='bbsList bbs01')

    if not table:
        print("ê³µì§€ì‚¬í•­ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return notices

    tbody = table.find('tbody')
    if not tbody:
        print("í…Œì´ë¸” ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return notices

    rows = tbody.find_all('tr')

    for row in rows:
        cells = row.find_all('td')
        if len(cells) >= 6:
            title_cell = cells[2]  # ì œëª© ì»¬ëŸ¼
            title_link = title_cell.find('a')
            if title_link:
                title_span = title_link.find('span')
                if title_span:
                    title = title_span.get_text(strip=True)
                    link = 'https://www.jjss.or.kr/reserv/planweb/board/' + title_link['href']
                    date = cells[4].get_text(strip=True)  # ë“±ë¡ì¼

                    # "ì‹ ê·œ" ë˜ëŠ” "ì´ˆê¸‰" í‚¤ì›Œë“œ í•„í„°ë§
                    if "ì‹ ê·œ" in title or "ì´ˆê¸‰" in title:
                        notices.append({
                            'title': title,
                            'link': link,
                            'date': date
                        })
                        print(f"ë°œê²¬ëœ ê³µì§€: {title}")

    return notices


async def main():
    try:
        # ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡
        start_message = """
ğŸŠâ€â™€ï¸ <b>ì™„ì‚°ìˆ˜ì˜ì¥ ì‹ ê·œ/ì´ˆê¸‰ ì•Œë¦¼ë´‡ ì‹œì‘!</b>

âœ… ë´‡ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.
ğŸ” "ì‹ ê·œ" ë˜ëŠ” "ì´ˆê¸‰" í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê³µì§€ì‚¬í•­ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
â° 2ì‹œê°„ë§ˆë‹¤ í™•ì¸í•©ë‹ˆë‹¤.

ğŸ“… ì‹œì‘ ì‹œê°„: {}
        """.format(datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")).strip()

        await send_telegram_message(start_message)

        current_notices = crawl_notices()

        # ì´ì „ ê³µì§€ì‚¬í•­ ë°ì´í„° ë¡œë“œ
        try:
            with open('data/last_posts.json', 'r', encoding='utf-8') as f:
                last_notices = json.load(f)
        except FileNotFoundError:
            last_notices = []

        # ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ ì°¾ê¸°
        last_titles = {notice['title'] for notice in last_notices}
        new_notices = [notice for notice in current_notices
                       if notice['title'] not in last_titles]

        print(f"ì „ì²´ ê³µì§€: {len(current_notices)}ê°œ, ìƒˆ ê³µì§€: {len(new_notices)}ê°œ")

        # ìƒˆ ê³µì§€ì‚¬í•­ì´ ìˆìœ¼ë©´ í…”ë ˆê·¸ë¨ ì „ì†¡
        if new_notices:
            for notice in new_notices:
                message = f"""
ğŸŠâ€â™€ï¸ <b>ì™„ì‚°ìˆ˜ì˜ì¥ ì‹ ê·œ/ì´ˆê¸‰ ê³µì§€</b>

ğŸ“‹ <b>{notice['title']}</b>
ğŸ“… ë“±ë¡ì¼: {notice['date']}
ğŸ”— <a href="{notice['link']}">ê³µì§€ì‚¬í•­ ë³´ê¸°</a>
                """.strip()
                await send_telegram_message(message)
                time.sleep(1)  # ë©”ì‹œì§€ ê°„ 1ì´ˆ ê°„ê²©
        else:
            print("ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

        # í˜„ì¬ ê³µì§€ì‚¬í•­ ì €ì¥
        os.makedirs('data', exist_ok=True)
        with open('data/last_posts.json', 'w', encoding='utf-8') as f:
            json.dump(current_notices, f, ensure_ascii=False, indent=2)

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì „ì†¡ (HTML íŒŒì‹± ì—ëŸ¬ ë°©ì§€)
        error_message = f"""âŒ ì™„ì‚°ìˆ˜ì˜ì¥ ì•Œë¦¼ë´‡ ì˜¤ë¥˜ ë°œìƒ

ì˜¤ë¥˜ ë‚´ìš©: {str(e)[:200]}
ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ì‹œë„ë©ë‹ˆë‹¤."""

        await send_telegram_message(error_message, use_html=False)


if __name__ == "__main__":
    asyncio.run(main())
